sudo apt install openjdk-8-jdk
ls /usr/lib/jvm/java-8-openjdk-amd64
nano ~/.bashrc
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
source .bashrc
echo $JAVA_HOME

#Paswordless SSH
sudo apt-get install openssh-server openssh-client
ssh localhost
ssh-keygen -t rsa -P ""
cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
ssh localhost

#Hadoop Installation 
mkdir -p course/softwares
cd course/softwares
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz 
mv hadoop-3.3.4.tar.gz course/softwares
tar -xzvf hadoop-3.3.4.tar.gz

ls
nano ~/.bashrc
export HADOOP_HOME=$HOME/Desktop/trialrun/softwares/hadoop-3.3.4
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
source .bashrc
hadoop version


 Pseudo Distributed mode
nano ~/.bashrc

export HADOOP_HOME=$HOME/Desktop/trialrun/softwares/hadoop-3.3.4
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_YARN_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_INSTALL=$HADOOP_HOME
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
export HADOOP_OPTS="-Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR"
export HADOOP_SECURITY_CONF_DIR

source ~/.bashrc

hadoop version
cd $HADOOP_HOME/etc/hadoop

nano hadoop-env.sh 
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

nano core-site.xml
<configuration>

   <property> 
      <name>fs.default.name</name> 
      <value>hdfs://localhost:9000</value> 
   </property>
   
</configuration>

nano hdfs-site.xml
<configuration>

   <property> 
      <name>dfs.replication</name> 
      <value>1</value> 
   </property> 
   <property> 
      <name>dfs.name.dir</name> 
      <value>PATH </value> 
   </property> 
   <property> 
      <name>dfs.data.dir</name>
      <value>PATH </value > 
   </property>
   
</configuration>

nano yarn-site.xml
<configuration>

   <property> 
      <name>yarn.nodemanager.aux-services</name> 
      <value>mapreduce_shuffle</value> 
   </property>
   
</configuration>

nano mapred-site.xml
<configuration>

   <property> 
      <name>mapreduce.framework.name</name> 
      <value>yarn</value> 
   </property>

</configuration>



#Starting the nodes
start-dfs.sh #starts the dfs
start-yarn.sh #starts the yarn